# -*- coding: utf-8 -*-  
'''
GoogleLeNet给出的设计原则：
    1 避免表达瓶颈，特别是在网络靠前的地方。 
        信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。
        从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。
        比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。 
        另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）
    2 高维特征更易处理。 高维特征更易区分，会加快训练。
    3 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息。 
        比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。
    4 平衡网络的宽度与深度。
    5 非对称卷积不要用在靠近输入的层，会影响精度，要用在较高的层
      非对称卷积在图片大小介于12×12到20×20大小之间的时候，效果比较好

'''